from __future__ import annotations

import argparse
from pathlib import Path
from urllib.parse import parse_qs, urlparse
from typing import Any, Dict, Iterable, List, Optional, Tuple

# Optional imports: keep tests runnable even if deps are missing
try:
    from yt_dlp import YoutubeDL  # type: ignore
except ImportError:  # pragma: no cover - optional runtime dependency
    YoutubeDL = None

try:
    from youtube_transcript_api import (  # type: ignore
        NoTranscriptFound,
        TranscriptsDisabled,
        YouTubeTranscriptApi,
    )
except ImportError:  # pragma: no cover - optional runtime dependency
    NoTranscriptFound = TranscriptsDisabled = YouTubeTranscriptApi = None
    VideoUnavailable = IpBlocked = None
else:
    try:
        from youtube_transcript_api._errors import IpBlocked, VideoUnavailable  # type: ignore
    except Exception:  # pragma: no cover - optional runtime dependency
        IpBlocked = VideoUnavailable = None
import time


def format_timestamp(seconds: float) -> str:
    """Format seconds into [HH:MM:SS] or [MM:SS]."""
    total_seconds = int(seconds)
    hours, remainder = divmod(total_seconds, 3600)
    minutes, secs = divmod(remainder, 60)
    if hours:
        return f"[{hours:02d}:{minutes:02d}:{secs:02d}]"
    return f"[{minutes:02d}:{secs:02d}]"


def chunk_transcript(
    transcript: List[Dict[str, Any]],
    max_gap_seconds: float = 30.0,
    max_chars: int = 500,
) -> List[Dict[str, Any]]:
    """
    Group adjacent caption lines into readable paragraphs.

    - Starts a new chunk when the gap between caption starts exceeds `max_gap_seconds`
      or the accumulated text would exceed `max_chars`.
    """
    if not transcript:
        return []

    chunks: List[Dict[str, Any]] = []
    current_text: List[str] = []
    current_start: float = transcript[0].get("start", 0.0)
    current_end: float = current_start

    for entry in transcript:
        text = entry.get("text", "").strip()
        if not text:
            continue
        start = entry.get("start", 0.0)
        accumulated = sum(len(t) for t in current_text)
        if current_text and ((start - current_start) >= max_gap_seconds or (accumulated + len(text)) > max_chars):
            chunks.append({"start": current_start, "end": current_end, "text": " ".join(current_text)})
            current_text = [text]
            current_start = start
            current_end = start + entry.get("duration", 0.0)
        else:
            if not current_text:
                current_start = start
            current_text.append(text)
            current_end = start + entry.get("duration", 0.0)

    if current_text:
        # If we never advanced end (e.g., missing duration), give a reasonable end window.
        if current_end <= current_start:
            current_end = current_start + max_gap_seconds
        chunks.append({"start": current_start, "end": current_end, "text": " ".join(current_text)})

    return chunks


def parse_existing_markdown(path: Path) -> Tuple[Optional[str], List[Dict[str, Any]]]:
    """
    Parse an existing consolidated transcript markdown (generated by this tool)
    back into structured entries. Useful for reformatting without re-fetching.
    """
    import re

    playlist_title: Optional[str] = None
    entries: List[Dict[str, Any]] = []
    transcript: List[Dict[str, Any]] = []
    current_index: Optional[int] = None
    current_title: Optional[str] = None

    summary_re = re.compile(r"<summary>\s*(\d+)\s*-\s*(.*?)</summary>")
    ts_re = re.compile(r"^\[(\d{2}):(\d{2})(?::(\d{2}))?\](?:–\[[0-9:.]+\])?\s*(.*)")

    lines = path.read_text(encoding="utf-8").splitlines()
    for line in lines:
        if line.startswith("# "):
            playlist_title = line[2:].strip()
        match_summary = summary_re.match(line.strip())
        if match_summary:
            # Flush previous entry
            if current_title is not None:
                entries.append(
                    {
                        "index": current_index or len(entries) + 1,
                        "title": current_title,
                        "transcript": transcript,
                    }
                )
                transcript = []
            current_index = int(match_summary.group(1))
            current_title = match_summary.group(2).strip()
            continue

        if line.strip() == "</details>":
            if current_title is not None:
                entries.append(
                    {
                        "index": current_index or len(entries) + 1,
                        "title": current_title,
                        "transcript": transcript,
                    }
                )
            transcript = []
            current_index = None
            current_title = None
            continue

        clean_line = line.strip()
        if clean_line.startswith(("- ", "* ")):
            clean_line = clean_line[2:].strip()

        ts_match = ts_re.match(clean_line)
        if ts_match:
            hours = ts_match.group(3)
            minutes = int(ts_match.group(1))
            seconds = int(ts_match.group(2))
            total_seconds = seconds + (minutes * 60) + (int(hours) * 3600 if hours else 0)
            text = ts_match.group(4).strip()
            transcript.append({"start": float(total_seconds), "text": text})

    return playlist_title, entries


def sanitize_filename(name: str) -> str:
    """Sanitize a string to be safe for filenames."""
    import re
    return re.sub(r'[<>:"/\\|?*]', '_', name).strip()


def render_video_markdown(
    entry: Dict[str, Any],
    include_timestamps: bool,
    style: str = "paragraph",
    chunk_kwargs: Optional[Dict[str, Any]] = None,
) -> str:
    """Render a single video transcript as a standalone markdown file."""
    title = entry.get("title", "Untitled")
    upload_date = entry.get("upload_date")
    date_str = f" ({upload_date})" if upload_date else ""
    
    lines = [f"# {title}{date_str}", ""]
    
    transcript = entry.get("transcript")
    if transcript:
        for chunk in chunk_transcript(transcript, **(chunk_kwargs or {})):
            prefix = f"{format_timestamp(chunk['start'])} " if include_timestamps else ""
            if include_timestamps and chunk.get("end") is not None:
                prefix = f"{format_timestamp(chunk['start'])}–{format_timestamp(chunk['end'])} "
            
            if style == "bullet":
                lines.append(f"- {prefix}{chunk['text']}".strip())
            else:
                lines.append(f"{prefix}{chunk['text']}".strip())
                lines.append("")
    else:
        lines.append("_no transcript available_")
        lines.append("")
        
    return "\n".join(lines)


def build_collapsible_section(
    title: str,
    transcript: Optional[List[Dict[str, Any]]],
    include_timestamps: bool,
    style: str = "paragraph",
    chunk_kwargs: Optional[Dict[str, Any]] = None,
) -> str:
    """Create a collapsible markdown section for a single video transcript."""
    lines: List[str] = ["<details>", f"<summary>{title}</summary>", ""]
    if transcript:
        for chunk in chunk_transcript(transcript, **(chunk_kwargs or {})):
            prefix = f"{format_timestamp(chunk['start'])} " if include_timestamps else ""
            if include_timestamps and chunk.get("end") is not None:
                prefix = f"{format_timestamp(chunk['start'])}–{format_timestamp(chunk['end'])} "
            if style == "bullet":
                lines.append(f"- {prefix}{chunk['text']}".strip())
            else:
                lines.append(f"{prefix}{chunk['text']}".strip())
                lines.append("")  # blank line between paragraphs
    else:
        lines.append("_no transcript available_")
        lines.append("")
    lines.extend(["</details>", ""])
    return "\n".join(lines)


def render_consolidated(
    entries: Iterable[Dict[str, Any]],
    include_timestamps: bool,
    playlist_title: Optional[str] = None,
    style: str = "paragraph",
    chunk_kwargs: Optional[Dict[str, Any]] = None,
) -> str:
    """Render the full playlist transcript markdown with collapsible per-video sections."""
    title = playlist_title or "Playlist Transcript"
    parts = [f"# {title}", ""]
    for entry in sorted(entries, key=lambda e: e.get("index", 0)):
        display_title = f"{entry.get('index', 0):02d} - {entry.get('title', 'Untitled')}"
        parts.append(
            build_collapsible_section(
                title=display_title,
                transcript=entry.get("transcript"),
                include_timestamps=include_timestamps,
                style=style,
                chunk_kwargs=chunk_kwargs,
            )
        )
    return "\n".join(parts)


def fetch_playlist_videos(playlist_url: str) -> Tuple[Optional[str], List[Dict[str, Any]]]:
    """Fetch playlist metadata and return (title, videos)."""
    if YoutubeDL is None:
        raise ImportError("yt_dlp is required to fetch playlist data. Install via pip install yt-dlp.")

    opts = {"quiet": True, "skip_download": True, "extract_flat": True}
    with YoutubeDL(opts) as ydl:  # type: ignore
        info = ydl.extract_info(playlist_url, download=False)
        # If a watch URL with a playlist param is supplied, retry with the canonical playlist URL.
        if info.get("_type") != "playlist":
            qs = parse_qs(urlparse(playlist_url).query)
            list_id = qs.get("list", [None])[0]
            if list_id:
                canonical = f"https://www.youtube.com/playlist?list={list_id}"
                info = ydl.extract_info(canonical, download=False)

    playlist_title = info.get("title")
    entries = info["entries"] if info.get("_type") == "playlist" else [info]
    videos = []
    for idx, entry in enumerate(entries, 1):
        videos.append(
            {
                "index": idx,
                "id": entry["id"],
                "title": entry.get("title", f"Video {idx}"),
                "upload_date": entry.get("upload_date"),
            }
        )
    return playlist_title, videos


def fetch_video_transcript(video_id: str, languages: Optional[List[str]] = None) -> Optional[List[Dict[str, Any]]]:
    """Fetch a video's transcript if available; return None when missing."""
    if YouTubeTranscriptApi is None:
        raise ImportError(
            "youtube-transcript-api is required to fetch transcripts. Install via pip install youtube-transcript-api."
        )
    attempts = 3
    for idx in range(attempts):
        try:
            fetched = YouTubeTranscriptApi().fetch(video_id, languages=languages or ["en"])  # type: ignore
            return [{"text": snippet.text, "start": snippet.start, "duration": snippet.duration} for snippet in fetched]
        except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):
            return None
        except IpBlocked:
            if idx == attempts - 1:
                raise
            time.sleep(5)


def write_markdown(output_path: Path, content: str) -> None:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(content, encoding="utf-8")

def main() -> None:
    parser = argparse.ArgumentParser(description="Export playlist transcripts to a single markdown with collapsible sections.")
    parser.add_argument("playlist_url", help="YouTube playlist URL (ignored if --from-markdown is used)")
    parser.add_argument("--out", default="playlist_transcript.md", help="Output markdown path")
    parser.add_argument("--timestamps", action="store_true", help="Include timestamps for each paragraph chunk")
    parser.add_argument(
        "--style",
        choices=["paragraph", "bullet"],
        default="paragraph",
        help="Render style for transcript chunks (paragraph or bullet).",
    )
    parser.add_argument(
        "--max-gap-seconds",
        type=float,
        default=30.0,
        help="Start a new chunk when the gap between captions exceeds this many seconds (default: 30).",
    )
    parser.add_argument(
        "--max-chars",
        type=int,
        default=500,
        help="Start a new chunk when accumulated characters exceed this length (default: 500).",
    )
    parser.add_argument(
        "--from-markdown",
        help="Reformat an existing consolidated transcript markdown instead of fetching fresh transcripts.",
    )
    parser.add_argument(
        "--languages",
        nargs="+",
        default=["en"],
        help="Language codes to request transcripts in order of preference (default: en)",
    )
    parser.add_argument(
        "--sort-by-date",
        action="store_true",
        help="Sort videos by upload date (oldest first).",
    )
    parser.add_argument(
        "--output-dir",
        help="Output directory for individual video files. If set, --out is ignored for the file path.",
    )
    args = parser.parse_args()

    if args.from_markdown:
        playlist_title, entries = parse_existing_markdown(Path(args.from_markdown))
    else:
        playlist_title, videos = fetch_playlist_videos(args.playlist_url)
        
        # If sorting by date is requested, ensure we have upload dates.
        # extraction_flat=True often skips dates. If missing, we must fetch details.
        if args.sort_by_date and videos and not videos[0].get("upload_date"):
            if YoutubeDL:
                print("Fetching video metadata to get upload dates...")
                ydl_opts = {"quiet": True, "skip_download": True}
                with YoutubeDL(ydl_opts) as ydl:
                    for video in videos:
                        try:
                            info = ydl.extract_info(video["id"], download=False)
                            video["upload_date"] = info.get("upload_date")
                        except Exception as e:
                            print(f"Could not fetch metadata for {video['id']}: {e}")

        entries = []
        for video in videos:
            transcript = fetch_video_transcript(video_id=video["id"], languages=args.languages)
            entries.append({**video, "transcript": transcript})

    # Sort if requested
    if args.sort_by_date:
        # Sort by upload_date (strings like '20210101' sort correctly). 
        # Handle missing dates by putting them at the end or beginning? 
        # Let's put them at the end.
        entries.sort(key=lambda x: x.get("upload_date") or "99999999")

    chunk_kwargs = {"max_gap_seconds": args.max_gap_seconds, "max_chars": args.max_chars}

    if args.output_dir:
        out_dir = Path(args.output_dir)
        out_dir.mkdir(parents=True, exist_ok=True)
        
        for entry in entries:
            date_prefix = entry.get("upload_date", "")
            if not date_prefix:
                # Fallback to index if no date, or just leave it. 
                # User wants chronological ordering.
                # If we sorted, the order is correct, but filenames need to reflect it 
                # so they sort in file explorer.
                # If sort_by_date is on, we might use an index prefix based on the new sort order?
                # Or just use the date.
                pass
            
            # Construct filename: "YYYYMMDD - Title.md" or "01 - Title.md"
            # If we have a date, use it.
            title = sanitize_filename(entry.get("title", "video"))
            if date_prefix:
                filename = f"{date_prefix} - {title}.md"
            else:
                # If no date, maybe use index?
                idx = entry.get("index", 0)
                filename = f"{idx:02d} - {title}.md"
            
            content = render_video_markdown(
                entry, 
                include_timestamps=args.timestamps, 
                style=args.style,
                chunk_kwargs=chunk_kwargs
            )
            write_markdown(out_dir / filename, content)
        print(f"Wrote {len(entries)} files to {out_dir}")

    else:
        content = render_consolidated(
            entries,
            include_timestamps=args.timestamps,
            playlist_title=playlist_title,
            style=args.style,
            chunk_kwargs=chunk_kwargs,
        )
        output_path = Path(args.out)
        write_markdown(output_path, content)
        print(f"Wrote {output_path} with {len(entries)} videos.")


if __name__ == "__main__":  # pragma: no cover
    main()
